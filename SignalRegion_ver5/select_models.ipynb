{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Global Variables\n",
    "CHANNEL = \"1E2Mu\"\n",
    "MASS_POINTS = [\n",
    "    \"MHc70_MA15\", \"MHc70_MA40\", \"MHc70_MA65\",\n",
    "    \"MHc100_MA15\", \"MHc100_MA25\", \"MHc100_MA60\", \"MHc100_MA95\",\n",
    "    \"MHc130_MA15\", \"MHc130_MA45\", \"MHc130_MA55\", \"MHc130_MA90\", \"MHc130_MA125\",\n",
    "    \"MHc160_MA15\", \"MHc160_MA45\", \"MHc160_MA75\", \"MHc160_MA85\", \"MHc160_MA120\", \"MHc160_MA155\"\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "best_estimators = dict()\n",
    "best_estimators[\"mass_point\"] = MASS_POINTS\n",
    "best_estimators[\"lr_fake\"] = []\n",
    "best_estimators[\"n_hidden_fake\"] = []\n",
    "best_estimators[\"lr_ttX\"] = []\n",
    "best_estimators[\"n_hidden_ttX\"] = []\n",
    "\n",
    "# fakes\n",
    "for mass_point in MASS_POINTS:\n",
    "    df = pd.read_csv(f\"Outputs/{CHANNEL}/{mass_point}/metrics_vs_fake.csv\")\n",
    "    df = df[['index', 'auc_train', 'auc_valid', 'auc_test', 'ksprob_scipy', 'ksprob_root']]\n",
    "    df.set_index(\"index\", inplace=True)\n",
    "    \n",
    "    auc_max = 0.\n",
    "    index = None\n",
    "    for idx in df.index:\n",
    "        ksprob = df.loc[idx, 'ksprob_root']\n",
    "        auc_valid = df.loc[idx, 'auc_valid']\n",
    "        auc_test = df.loc[idx, 'auc_test']\n",
    "        \n",
    "        # check whether the model meets the criteria\n",
    "        if ksprob > 0.3 and abs(auc_valid - auc_test)/auc_test < 0.01:\n",
    "            if auc_max < auc_valid:\n",
    "                auc_max = auc_valid\n",
    "                index = idx\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    # get learning rates and n_hidden from index\n",
    "    tokens = index.split(\"_\")\n",
    "    lr = tokens[0].split(\"-\")[1]\n",
    "    n_hidden = tokens[1].split(\"-\")[1]\n",
    "    best_estimators[\"lr_fake\"].append(lr)\n",
    "    best_estimators[\"n_hidden_fake\"].append(n_hidden)\n",
    "\n",
    "# ttX    \n",
    "for mass_point in MASS_POINTS:\n",
    "    df = pd.read_csv(f\"Outputs/{CHANNEL}/{mass_point}/metrics_vs_ttX.csv\")\n",
    "    df = df[['index', 'auc_train', 'auc_valid', 'auc_test', 'ksprob_scipy', 'ksprob_root']]\n",
    "    df.set_index(\"index\", inplace=True)\n",
    "    \n",
    "    auc_max = 0.\n",
    "    index = None\n",
    "    for idx in df.index:\n",
    "        ksprob = df.loc[idx, 'ksprob_root']\n",
    "        auc_valid = df.loc[idx, 'auc_valid']\n",
    "        auc_test = df.loc[idx, 'auc_test']\n",
    "        \n",
    "        # check whether the model meets the criteria\n",
    "        if ksprob > 0.3 and abs(auc_valid - auc_test)/auc_test < 0.01:\n",
    "            if auc_max < auc_valid:\n",
    "                auc_max = auc_valid\n",
    "                index = idx\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    # get learning rates and n_hidden from index\n",
    "    tokens = index.split(\"_\")\n",
    "    lr = tokens[0].split(\"-\")[1]\n",
    "    n_hidden = tokens[1].split(\"-\")[1]\n",
    "    best_estimators[\"lr_ttX\"].append(lr)\n",
    "    best_estimators[\"n_hidden_ttX\"].append(n_hidden)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "df = pd.DataFrame(best_estimators)\n",
    "df.set_index(\"mass_point\", inplace=True)\n",
    "df.to_csv(f\"Outputs/{CHANNEL}/CSV/hyper_params.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for key, value in best_estimators.items():\n",
    "    tokens = value[0].split(\"_\")\n",
    "    lr = tokens[0].split(\"-\")[1]\n",
    "    n_hidden = tokens[1].split(\"-\")[1]\n",
    "    print(f\"{key}: lr-{lr}, n_hidden-{n_hidden}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MHc70_MA15: lr-0.5, n_hidden-64\n",
      "MHc70_MA40: lr-0.6, n_hidden-256\n",
      "MHc70_MA65: lr-0.1, n_hidden-256\n",
      "MHc100_MA15: lr-0.5, n_hidden-192\n",
      "MHc100_MA25: lr-0.5, n_hidden-256\n",
      "MHc100_MA60: lr-0.6, n_hidden-256\n",
      "MHc100_MA95: lr-0.1, n_hidden-192\n",
      "MHc130_MA15: lr-0.4, n_hidden-192\n",
      "MHc130_MA45: lr-0.6, n_hidden-192\n",
      "MHc130_MA55: lr-0.6, n_hidden-128\n",
      "MHc130_MA90: lr-0.6, n_hidden-256\n",
      "MHc130_MA125: lr-0.6, n_hidden-64\n",
      "MHc160_MA15: lr-0.6, n_hidden-128\n",
      "MHc160_MA45: lr-0.5, n_hidden-256\n",
      "MHc160_MA75: lr-0.5, n_hidden-192\n",
      "MHc160_MA85: lr-0.6, n_hidden-256\n",
      "MHc160_MA120: lr-0.6, n_hidden-64\n",
      "MHc160_MA155: lr-0.6, n_hidden-64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "da2e8bb8865a0bc8a86a0de3eb19f1fa75363a21fa8fa429cd630896f2163dc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}