{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Global Variables\n",
    "CHANNEL = \"3Mu\"\n",
    "MASS_POINTS = [\n",
    "    \"MHc70_MA15\", \"MHc70_MA40\", \"MHc70_MA65\",\n",
    "    \"MHc100_MA15\", \"MHc100_MA25\", \"MHc100_MA60\", \"MHc100_MA95\",\n",
    "    \"MHc130_MA15\", \"MHc130_MA45\", \"MHc130_MA55\", \"MHc130_MA90\", \"MHc130_MA125\",\n",
    "    \"MHc160_MA15\", \"MHc160_MA45\", \"MHc160_MA75\", \"MHc160_MA85\", \"MHc160_MA120\", \"MHc160_MA155\"\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "best_estimators = dict()\n",
    "best_estimators[\"mass_point\"] = MASS_POINTS\n",
    "best_estimators[\"lr_fake\"] = []\n",
    "best_estimators[\"n_hidden_fake\"] = []\n",
    "best_estimators[\"lr_ttX\"] = []\n",
    "best_estimators[\"n_hidden_ttX\"] = []\n",
    "\n",
    "# fakes\n",
    "for mass_point in MASS_POINTS:\n",
    "    df = pd.read_csv(f\"Outputs/{CHANNEL}/{mass_point}/metrics_vs_fake.csv\")\n",
    "    df = df[['index', 'auc_train', 'auc_valid', 'auc_test', 'ksprob_scipy', 'ksprob_root']]\n",
    "    df.set_index(\"index\", inplace=True)\n",
    "    \n",
    "    auc_max = 0.\n",
    "    index = None\n",
    "    for idx in df.index:\n",
    "        ksprob = df.loc[idx, 'ksprob_root']\n",
    "        auc_valid = df.loc[idx, 'auc_valid']\n",
    "        auc_test = df.loc[idx, 'auc_test']\n",
    "        \n",
    "        # check whether the model meets the criteria\n",
    "        if ksprob > 0.3 and abs(auc_valid - auc_test)/auc_test < 0.01:\n",
    "            if auc_max < auc_valid:\n",
    "                auc_max = auc_valid\n",
    "                index = idx\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    # get learning rates and n_hidden from index\n",
    "    tokens = index.split(\"_\")\n",
    "    lr = tokens[0].split(\"-\")[1]\n",
    "    n_hidden = tokens[1].split(\"-\")[1]\n",
    "    best_estimators[\"lr_fake\"].append(lr)\n",
    "    best_estimators[\"n_hidden_fake\"].append(n_hidden)\n",
    "\n",
    "# ttX    \n",
    "for mass_point in MASS_POINTS:\n",
    "    df = pd.read_csv(f\"Outputs/{CHANNEL}/{mass_point}/metrics_vs_ttX.csv\")\n",
    "    df = df[['index', 'auc_train', 'auc_valid', 'auc_test', 'ksprob_scipy', 'ksprob_root']]\n",
    "    df.set_index(\"index\", inplace=True)\n",
    "    \n",
    "    auc_max = 0.\n",
    "    index = None\n",
    "    for idx in df.index:\n",
    "        ksprob = df.loc[idx, 'ksprob_root']\n",
    "        auc_valid = df.loc[idx, 'auc_valid']\n",
    "        auc_test = df.loc[idx, 'auc_test']\n",
    "        \n",
    "        # check whether the model meets the criteria\n",
    "        if ksprob > 0.3 and abs(auc_valid - auc_test)/auc_test < 0.01:\n",
    "            if auc_max < auc_valid:\n",
    "                auc_max = auc_valid\n",
    "                index = idx\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    # get learning rates and n_hidden from index\n",
    "    tokens = index.split(\"_\")\n",
    "    lr = tokens[0].split(\"-\")[1]\n",
    "    n_hidden = tokens[1].split(\"-\")[1]\n",
    "    best_estimators[\"lr_ttX\"].append(lr)\n",
    "    best_estimators[\"n_hidden_ttX\"].append(n_hidden)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df = pd.DataFrame(best_estimators)\n",
    "df.set_index(\"mass_point\", inplace=True)\n",
    "df.to_csv(f\"Outputs/{CHANNEL}/CSV/hyper_params.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for key, value in best_estimators.items():\n",
    "    print(key, value)\n",
    "    tokens = value[0].split(\"_\")\n",
    "    lr = tokens[0].split(\"-\")[1]\n",
    "    n_hidden = tokens[1].split(\"-\")[1]\n",
    "    print(f\"{key}: lr-{lr}, n_hidden-{n_hidden}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mass_point ['MHc70_MA15', 'MHc70_MA40', 'MHc70_MA65', 'MHc100_MA15', 'MHc100_MA25', 'MHc100_MA60', 'MHc100_MA95', 'MHc130_MA15', 'MHc130_MA45', 'MHc130_MA55', 'MHc130_MA90', 'MHc130_MA125', 'MHc160_MA15', 'MHc160_MA45', 'MHc160_MA75', 'MHc160_MA85', 'MHc160_MA120', 'MHc160_MA155']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3285500/506806265.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mn_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{key}: lr-{lr}, n_hidden-{n_hidden}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "da2e8bb8865a0bc8a86a0de3eb19f1fa75363a21fa8fa429cd630896f2163dc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}